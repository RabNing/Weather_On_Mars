# Web_scraping_challenge
![image](https://github.com/RabNing/Web_Scraping/assets/126477871/3d42e308-f3ca-4130-a7dd-784e865a56df)

# Project Background
You’re now ready to take on a full web-scraping and data analysis project. You’ve learned to identify HTML elements on a page, identify their id and class attributes, and use this knowledge to extract information via both automated browsing with Splinter and HTML parsing with Beautiful Soup. You’ve also learned to scrape various types of information. These include HTML tables and recurring elements, like multiple news articles on a webpage.
As you work on this Challenge, remember that you’re strengthening the same core skills that you’ve been developing until now: collecting data, organizing and storing data, analyzing data, and then visually communicating your insights.



The Web_scraping_challenge folder contains 2 scripts and a exported csv file.
The part_1_mars_news_NG.ipynbscrape titles and preview text from Mars news articles (https://static.bc-edx.com/data/web/mars_news/index.html), and print the content into dictionaries in a Python list in the notebook.
The part_2_mars_weather_NG.ipynb scrape and analyze Mars weather data, which exists in a table (https://static.bc-edx.com/data/web/mars_facts/temperature.html), and analyze Mars weather data as below, results are plotted to charts in the notebook:
   How many months exist on Mars?
   How many Martian (and not Earth) days worth of data exist in the scraped dataset?
   What are the coldest and the warmest months on Mars (at the location of Curiosity)? 
   Which months have the lowest and the highest atmospheric pressure on Mars? 
   Find the average daily atmospheric pressure of all the months.
   Export the DataFrame to a CSV file.
The Mars Temperature Data_NG.csv is an exported DataFrame of part 2.
